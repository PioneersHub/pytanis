{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import tomli\n",
    "import numpy as np\n",
    "import structlog\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16, 9.)})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging level\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytanis\n",
    "from pytanis import GSheetsClient, PretalxClient\n",
    "from pytanis.pretalx import subs_as_df, reviews_as_df, speakers_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be aware that this notebook might only run with the following version\n",
    "pytanis.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import event-specific settings to don't have them here in the notebook\n",
    "with open('config.toml', 'rb') as fh:\n",
    "    cfg = tomli.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretalx_client = PretalxClient(blocking=True)\n",
    "subs_count, subs = pretalx_client.submissions(cfg['event_name'], params={'questions': 'all'})\n",
    "spkrs_count, spkrs = pretalx_client.speakers(cfg['event_name'], params={'questions': 'all'})\n",
    "revs_count, revs = pretalx_client.reviews(cfg['event_name'])\n",
    "subs, revs, spkrs = list(subs), list(revs), list(spkrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df = subs_as_df(subs, with_questions=True)\n",
    "revs_df = reviews_as_df(revs)\n",
    "spkrs_df = speakers_as_df(spkrs, with_questions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for all submitted talks\n",
    "talks_df = subs_df.loc[subs_df['State'] == 'submitted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_tracks = ['PyData', 'PyCon', 'General']\n",
    "all_tracks = ['PyCon: MLOps & DevOps', 'PyCon: Programming & Software Engineering', 'PyCon: Python Language & Ecosystem', 'PyCon: Security', 'PyCon: Testing', 'PyCon: Django & Web', 'PyData: Data Handling & Data Engineering', 'PyData: Machine Learning & Deep Learning & Statistics', 'PyData: Natural Language Processing & Audio (incl. Generative AI NLP)', 'PyData: Computer Vision (incl. Generative AI CV)', 'PyData: Generative AI', 'PyData: Embedded Systems & Robotics', 'PyData: PyData & Scientific Libraries Stack', 'PyData: Visualisation & Jupyter', 'PyData: Research Software Engineering', 'General: Community & Diversity', 'General: Education, Career & Life', 'General: Ethics & Privacy', 'General: Infrastructure - Hardware & Cloud', 'General: Others']\n",
    "\n",
    "# all available submission types\n",
    "submission_types = talks_df['Submission type'].unique()\n",
    "\n",
    "# all available expertise levels\n",
    "expertise_levels = list(talks_df['Q: Expected audience expertise: Domain'].unique()) + list(talks_df['Q: Expected audience expertise: Python'].unique())\n",
    "expertise_levels = list(set(expertise_levels))\n",
    "\n",
    "# all expertise categories\n",
    "expertise_categories = ['Q: Expected audience expertise: Python', 'Q: Expected audience expertise: Domain']\n",
    "\n",
    "# create an dataframe with 'all_tracks' and all 'submission_types' as rows\n",
    "tracks_df = pd.DataFrame(all_tracks, columns=['Track'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All independent of submission type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group submittaded talks by track and count the number of submissions\n",
    "talks_quantification_by_domain_expertise = talks_df.groupby(['Track', 'Q: Expected audience expertise: Domain']).size().unstack(fill_value=0)\n",
    "talks_quantification_by_domain_expertise = tracks_df.join(talks_quantification_by_domain_expertise, on='Track')\n",
    "talks_quantification_by_domain_expertise['Total'] = talks_quantification_by_domain_expertise[['None', 'Novice', 'Intermediate', 'Advanced']].sum(axis=1)\n",
    "talks_quantification_by_domain_expertise['Total %'] = (talks_quantification_by_domain_expertise['Total'] / talks_quantification_by_domain_expertise['Total'].sum() * 100).round(2)\n",
    "talks_quantification_by_domain_expertise['Main Track'] = talks_quantification_by_domain_expertise['Track'].apply(lambda x: x.split(':')[0] if ':' in x else x)\n",
    "talks_quantification_by_domain_expertise['Total % per Main Track'] = talks_quantification_by_domain_expertise.groupby('Main Track')['Total'].transform(lambda x: (x / x.sum() * 100).round(2))\n",
    "\n",
    "# reorder columns\n",
    "talks_quantification_by_domain_expertise = talks_quantification_by_domain_expertise[['Main Track', 'Track', 'Total', 'Total %', 'Total % per Main Track', 'None', 'Novice', 'Intermediate', 'Advanced']]\n",
    "talks_quantification_by_python_expertise = talks_df.groupby(['Track', 'Q: Expected audience expertise: Python']).size().unstack(fill_value=0)\n",
    "talks_quantification_by_python_expertise = tracks_df.join(talks_quantification_by_python_expertise, on='Track')\n",
    "talks_quantification_by_python_expertise['Main Track'] = talks_quantification_by_python_expertise['Track'].apply(lambda x: x.split(':')[0] if ':' in x else x)\n",
    "talks_quantification_by_python_expertise = talks_quantification_by_python_expertise[['Main Track', 'Track', 'None', 'Novice', 'Intermediate', 'Advanced']]\n",
    "\n",
    "# join talks_quantification_by_domain_expertise and talks_quantification_by_python_expertise and keep add a group column name fir the expertise level\n",
    "talks_quantification = pd.merge(talks_quantification_by_domain_expertise, talks_quantification_by_python_expertise, on=['Main Track', 'Track'], how='outer')\n",
    "\n",
    "talks_quantification.columns = pd.MultiIndex.from_tuples([\n",
    "    ('', col) if (col == 'Track') | (col == 'Total') | (col == 'Total %') | (col == 'Total % per Main Track') | (col == 'Main Track') else \n",
    "    ('Expected Domain Expertise by Audience', col.rstrip(\"_xy\")) if col.endswith('_x') else \n",
    "    ('Expected Python Expertise by Audience', col.rstrip(\"_xy\")) \n",
    "    for col in talks_quantification.columns\n",
    "])\n",
    "\n",
    "# fill NaN values with 0\n",
    "talks_quantification.fillna(0, inplace=True)\n",
    "\n",
    "talks_quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress overall table for plotting\n",
    "talks_quantification_condensed = talks_quantification.copy()\n",
    "\n",
    "talks_quantification_condensed['', 'Expected Domain Expertise by Audience'] = talks_quantification_condensed['Expected Domain Expertise by Audience'].to_numpy().tolist()\n",
    "talks_quantification_condensed['', 'Expected Python Expertise by Audience'] = talks_quantification_condensed['Expected Python Expertise by Audience'].to_numpy().tolist()\n",
    "\n",
    "talks_quantification_condensed = talks_quantification_condensed.drop(columns=['Expected Domain Expertise by Audience', 'Expected Python Expertise by Audience'], level=0)\n",
    "talks_quantification_condensed.columns = talks_quantification_condensed.columns.droplevel(0)\n",
    "\n",
    "# helper functions for plotting\n",
    "def cell_histogram_with_labels(values, global_max_value=None):\n",
    "    max_value = max(values) if global_max_value is None else global_max_value  # Maximalwert für Skalierung\n",
    "    bar_heights = [100 / len(values)] * len(values)  # Gleichmäßige Balkenhöhen (in Prozent)\n",
    "    bars = \"\"\n",
    "    labels = ['None', 'Novice', 'Intermediate', 'Advanced']\n",
    "    for i, value in enumerate(values):\n",
    "        label = labels[i]\n",
    "        bar_width = (value / max_value) * 100 if max_value > 0 else 0  # Width\n",
    "        y_position = i * bar_heights[0]  # Y-Position of each bar\n",
    "        # Rechteck (Bar)\n",
    "        bars += f'<rect x=\"0\" y=\"{y_position}%\" width=\"{bar_width}%\" height=\"{bar_heights[0]}%\" style=\"fill:#d65f5f50;\" />'\n",
    "        # Text (Label)\n",
    "        bars += f'<text x=\"2\" y=\"{y_position + bar_heights[0] / 1.8}%\" dominant-baseline=\"middle\" font-size=\"10\" fill=\"black\">{label} ({int(value)})</text>'\n",
    "    \n",
    "    svg = f\"\"\"\n",
    "    <svg width=\"100\" height=\"50\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 50\">\n",
    "        {bars}\n",
    "    </svg>\n",
    "    \"\"\"\n",
    "    return svg\n",
    "\n",
    "def single_value_histogram(value, max_value):\n",
    "    # Calculate the width of the bar as a percentage\n",
    "    bar_width = (value / max_value) * 100 if max_value > 0 else 0\n",
    "    \n",
    "    # Generate the SVG\n",
    "    svg = f\"\"\"\n",
    "    <svg width=\"100\" height=\"50\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 100 20\">\n",
    "        <!-- Rectangle (Bar) -->\n",
    "        <rect x=\"0\" y=\"-20\" width=\"{bar_width}%\" height=\"80\" style=\"fill:#d65f5f50;\" />\n",
    "        <!-- Text (Label) -->\n",
    "        <text x=\"5\" y=\"15\" font-size=\"14\" fill=\"black\">{round(value, 2)}%</text>\n",
    "    </svg>\n",
    "    \"\"\"\n",
    "    return svg\n",
    "\n",
    "# Generate output\n",
    "title = f'All {int(talks_quantification_condensed['Total'].sum())} submitted talks, long talks and tutorials (excluding pending submissions) <br> ****'\n",
    "\n",
    "talks_quantification_condensed_styled = talks_quantification_condensed.style \\\n",
    "    .set_caption(title) \\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'caption', 'props': [('font-family', 'Arial'), ('font-size', '20px'), ('font-weight', 'bold')]},\n",
    "        {'selector': 'th', 'props': [('font-family', 'Arial'), ('max-width', '160px')]}\n",
    "    ]) \\\n",
    "    .set_properties(**{'font-family': 'Arial'}) \\\n",
    "    .format({\n",
    "        ('Total'): '{:.0f}',\n",
    "        ('Total %'): lambda value: single_value_histogram(\n",
    "            value,\n",
    "            talks_quantification_condensed['Total %'].max()\n",
    "        ),\n",
    "        ('Total % per Main Track'): lambda value: single_value_histogram(\n",
    "            value,\n",
    "            talks_quantification_condensed['Total % per Main Track'].max()\n",
    "        ),\n",
    "        'Expected Domain Expertise by Audience': lambda values: cell_histogram_with_labels(\n",
    "            values,\n",
    "            np.concatenate(talks_quantification_condensed['Expected Domain Expertise by Audience'].to_numpy()).max()\n",
    "        ),\n",
    "        'Expected Python Expertise by Audience': lambda values: cell_histogram_with_labels(\n",
    "            values,\n",
    "            np.concatenate(talks_quantification_condensed['Expected Python Expertise by Audience'].to_numpy()).max()\n",
    "        ),\n",
    "    })\n",
    "\n",
    "talks_quantification_condensed_styled.to_html('talks_quantification.html', index=False, escape=False)\n",
    "\n",
    "talks_quantification_condensed_styled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for Talks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats for Talks (long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Todos\n",
    "- Compare against historical events\n",
    "- Split by submission type\n",
    "- make independent of submission type"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

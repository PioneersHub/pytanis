{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    " # Packages Loading and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import tomli\n",
    "import pandas as pd\n",
    "\n",
    "from pytanis import GSheetsClient, PretalxClient\n",
    "from pytanis.pretalx import subs_as_df\n",
    "from pytanis.review import Col\n",
    "import pytanis\n",
    "\n",
    "from helpers import (\n",
    "    setup_plotting, load_track_mapping, load_column_mapping,\n",
    "    build_reviews_df, prepare_submissions, prepare_reviewers, validate_mappings,\n",
    "    plot_reviews_per_proposal, plot_progress, plot_reviewer_stats,\n",
    "    assign_proposals, add_all_proposals_reviewers, save_assignments,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "setup_plotting()\n",
    "logging.basicConfig(level=logging.WARNING, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytanis.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../config.toml\", \"rb\") as fh:\n",
    "    cfg = tomli.load(fh)\n",
    "\n",
    "TARGET_REVIEWS = 3\n",
    "BUFFER_REVIEWS = 6\n",
    "COMMUNITY_MAP = (\n",
    "    \"General: Community, Diversity, Career, Life and everything else\",\n",
    "    \"General: Community\",\n",
    ")\n",
    "\n",
    "TRACK_MAPPING, PREF_ALIASES = load_track_mapping()\n",
    "COL_MAPPING = load_column_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    " # Read Reviews and all Submissions\n",
    " ## Connect to pretalx and pull the latest submissions and reviewys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretalx = PretalxClient(blocking=True)\n",
    "_, subs = pretalx.submissions(cfg[\"event_name\"])\n",
    "_, revs = pretalx.reviews(cfg[\"event_name\"])\n",
    "subs, revs = list(subs), list(revs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Optional (save the submissions locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./submission_state_2025-01-28.pkl\", \"wb\") as fh:\n",
    "    pickle.dump(subs, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    " ## Get Reviews and reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_df, revs_counts = build_reviews_df(revs)\n",
    "revs_user_df = revs_df.groupby(Col.pretalx_user).agg(list).reset_index()\n",
    "revs_user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    " ## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_df = prepare_submissions(subs_as_df, subs, revs_counts, TARGET_REVIEWS, COMMUNITY_MAP, TRACK_MAPPING)\n",
    "all_sub_codes = list(subs_df[Col.submission])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    " ## Some Statistics about the current Review Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviews_per_proposal(subs_df)\n",
    "plot_progress(subs_df, TARGET_REVIEWS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    " # Get spreadsheet with reviewers and preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gsheet = GSheetsClient()\n",
    "gsheet_df = gsheet.gsheet_as_df(cfg[\"reviewer_spread_id\"], cfg[\"reviewer_work_name\"])\n",
    "validate_mappings(revs_user_df, gsheet_df, COL_MAPPING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers_df, assign_all_emails = prepare_reviewers(\n",
    "    gsheet_df, revs_df, COL_MAPPING, COMMUNITY_MAP, PREF_ALIASES\n",
    ")\n",
    "reviewers_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    " ### Reviewer Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reviewer_stats(reviewers_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Reviewers who reviewed at least 1 submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers_df[[Col.speaker_name, Col.done_nreviews]][reviewers_df[Col.done_nreviews] > 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    " ### Check Track Mapping Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_prefs = {p for prefs in reviewers_df[Col.track_prefs] for p in prefs}\n",
    "sub_tracks = set(subs_df[Col.track].dropna())\n",
    "\n",
    "print(\"Submission tracks:\", sorted(sub_tracks))\n",
    "print(\"Reviewer preferences:\", sorted(reviewer_prefs))\n",
    "print(\"Missing coverage:\", sub_tracks - reviewer_prefs)\n",
    "print(\"Unused preferences:\", reviewer_prefs - sub_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    " # Assign proposals to reviewers\n",
    "\n",
    " The main idea is to assign each the number of needed reviews plus a buffer for a proposal/submission:\n",
    " * not a person having already assigned the review for a submission (no duplicates)\n",
    " * to a person having a preference for the track with the least amount of current work.\n",
    " * if no person has a preference for the track of the proposal, assign to someone with not much work.\n",
    " (it might be that someone gets by accident assigned his/her own proposal but Pretalx takes care of that if the same user e-mail was used)\n",
    "\n",
    " This is done initially. Then whenever this script is rerun, we remove all propoals from the review when the target review number is reached.\n",
    " We keep the current state, so that the initial number of proposals for review will only get smaller. From last year we learnt that reviewers\n",
    " hate it when we start assigning more and more work... who would have thought.\n",
    "\n",
    " Other considerations for the algorithm:\n",
    " * Don't have a state, i.e. do not depend on a former assignment json, been there, tried it, always causes trouble in the end\n",
    " * Make sure reviewers can visit submissions again which they already reviewed, i.e. make sure you do not remove already reviwed submission from a new assignment.\n",
    " * Keep in mind that there are always reviwers that sign up late for the party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude reviewers who requested all proposals from regular assignment\n",
    "regular_reviewers = reviewers_df[\n",
    "    ~reviewers_df[Col.all_proposals].apply(\n",
    "        lambda x: str(x).strip().lower() == \"x\" if pd.notna(x) else False\n",
    "    )\n",
    "]\n",
    "\n",
    "new_assign_df = assign_proposals(subs_df, regular_reviewers, buffer=BUFFER_REVIEWS)\n",
    "new_assign_df = add_all_proposals_reviewers(\n",
    "    new_assign_df, reviewers_df, assign_all_emails, all_sub_codes\n",
    ")\n",
    "\n",
    "print(f\"Final assignment shape: {new_assign_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = save_assignments(new_assign_df)\n",
    "print(f\"Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    " # Final reviewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_assign_df[[Col.speaker_name, Col.done_nreviews, \"Current #Assignments\"]]\n",
    "df.sort_values(Col.done_nreviews, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
